{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab02-2\n",
    "============\n",
    "\n",
    "###  Context\n",
    "#### Classification\n",
    "   + Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "Logistic Regression은 클래스 분류문제를 해결하기 위해 사용되는 것으로 독립 변수의 선형 결합으로 종속 변수를 설명하는 부분은 앞서 배운 선형 회귀(Linear Regression)와 같으나 그 결과가 특정 클래스일 확률로 나와 클래스 분류문제를 해결할 수 있는 방법입니다.\n",
    "\n",
    "## odds\n",
    "어떤 일이 발생할 상대적인 비율\n",
    "발생할 확률 p 와 발생하지 않을 확률 q(= 1- p)\n",
    "두 확률의 상대적인 비율\n",
    "\n",
    "![title](Images/ODD_F.png)\n",
    "\n",
    "## Log(odds)\n",
    "\n",
    "1. 0을 기준으로 상호 대칭적\n",
    "2. 계산이 용이\n",
    "\n",
    "![title](Images/ODD_G.png)\n",
    "\n",
    "## Logistic Function(sigmoid)\n",
    "해당 클래스일 확률 Y를 Log(odds)로 보고 이를 유도해보자\n",
    "\n",
    "![title](Images/sigmoid_F1.png)\n",
    "\n",
    "![title](Images/sigmoid_F2.png)\n",
    "\n",
    "위에 정리된 식을 가설 그래프로 나타내면\n",
    "\n",
    "![title](Images/sigmoid_G.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import optimize as op\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 살펴보기\n",
    "앞서 사용했던 붓꽃 데이터를 사용합니다.\n",
    "\n",
    "독립 변수로는 꽃받침 길이, 꽃받침 너비, 꽃잎의 길이, 꽃잎의 너비 데이터가 종속 변수로는 붓꽃 종(Species)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris_analysis = pd.read_csv(join('data', 'Iris.csv'))\n",
    "\n",
    "iris_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_setosa = iris_analysis.loc[iris_analysis['Species'] == 'Iris-setosa']\n",
    "iris_versicolor = iris_analysis.loc[iris_analysis['Species'] == 'Iris-versicolor']\n",
    "iris_virginica = iris_analysis.loc[iris_analysis['Species'] == 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "#꽃받침의 길이\n",
    "axs[0, 0].boxplot([iris_setosa['SepalLengthCm'], iris_versicolor['SepalLengthCm'], iris_virginica['SepalLengthCm']],\n",
    "           labels = ['seotosa', 'versicolor', 'virginica'],\n",
    "           meanline = True,\n",
    "           showmeans = True)\n",
    "axs[0, 0].set_title('Sepal length Boxplot')\n",
    "\n",
    "#꽃받침의 너비\n",
    "axs[0, 1].boxplot([iris_setosa['SepalWidthCm'], iris_versicolor['SepalWidthCm'], iris_virginica['SepalWidthCm']],\n",
    "           labels = ['seotosa', 'versicolor', 'virginica'],\n",
    "           meanline = True,\n",
    "           showmeans = True)\n",
    "axs[0, 1].set_title('Sepal width Boxplot')\n",
    "\n",
    "#꽃잎의 길이\n",
    "axs[1, 0].boxplot([iris_setosa['PetalLengthCm'], iris_versicolor['PetalLengthCm'], iris_virginica['PetalLengthCm']],\n",
    "           labels = ['seotosa', 'versicolor', 'virginica'],\n",
    "           meanline = True,\n",
    "           showmeans = True)\n",
    "axs[1, 0].set_title('Petal length Boxplot')\n",
    "\n",
    "#꽃잎의 너비\n",
    "axs[1, 1].boxplot([iris_setosa['PetalWidthCm'], iris_versicolor['PetalWidthCm'], iris_virginica['PetalWidthCm']],\n",
    "           labels = ['seotosa', 'versicolor', 'virginica'],\n",
    "           meanline = True,\n",
    "           showmeans = True)\n",
    "axs[1, 1].set_title('Petal width Boxplot')\n",
    "\n",
    "fig.subplots_adjust(left = 0.01, right = 2, bottom = 0.05, top = 2, hspace = 0.3, wspace = 0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = pd.read_csv(join('data', 'Iris.csv'))\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 간단한 전처리\n",
    "모든 독립 변수와 별개로 상수항을 추가하기 위해 ones함수를 이용하여 하나의 열을 추가하고 나머지 데이터를 다시 제자리에 저장합니다.\n",
    "\n",
    "학습용 데이터와 테스트용 데이터를 7:3의 비율로 나눕니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Species = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "#데이터의 수\n",
    "m = iris.shape[0]\n",
    "\n",
    "#독립 변수의 수\n",
    "n = 4\n",
    "\n",
    "#클래스 의 수\n",
    "k = 3\n",
    "\n",
    "X = np.ones((m,n + 1))\n",
    "y = np.array((m,1))\n",
    "\n",
    "X[:,1] = iris['PetalLengthCm'].values\n",
    "X[:,2] = iris['PetalWidthCm'].values\n",
    "X[:,3] = iris['SepalLengthCm'].values\n",
    "X[:,4] = iris['SepalWidthCm'].values\n",
    "\n",
    "y = iris['Species'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. scratch로 분류 해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid\n",
    "위의 유도한 Logistic Function으로 z에 독립 변수와 계수의 스칼라곱을 수행하여 활용할 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용함수\n",
    "실제 값과 연산으로 추정된 값간의 차이를 연산해주는 함수로 이 비용함수가 최소값을 가지게 하는 계수들의 집합(theta)를 찾는 것이 Logistic Regression의 목표이다. 최소값을 찾기위해 경사하강법을 사용하는데 이론 수업에서 자세히 다루지 않으므로 존재만 확인하고 넘어가자\n",
    "\n",
    "![title](Images/LRC_F.png)\n",
    "\n",
    "![title](Images/LRG_F.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regCostFunction(theta, X, y, _lambda = 0.1):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    reg = (_lambda/(2 * m)) * np.sum(theta**2)\n",
    "\n",
    "    return (1 / m) * (-y.T.dot(np.log(h)) - (1 - y).T.dot(np.log(1 - h))) + reg\n",
    "\n",
    "def regGradient(theta, X, y, _lambda = 0.1):\n",
    "    m, n = X.shape\n",
    "    theta = theta.reshape((n, 1))\n",
    "    y = y.reshape((m, 1))\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    reg = _lambda * theta /m\n",
    "\n",
    "    return ((1 / m) * X.T.dot(h - y)) + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logisticRegression(X, y, theta)\n",
    "위의 비용함수를 최소화한 결과를 scipy의 optimize.minimize를 이용하여 구하는 함수로 X에는 학습용 데이터, y에는 학습용 데이터의 답, theta에는 초기 계수들의 집합을 넣어 최적화된 계수들을 반환하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression(X, y, theta):\n",
    "    result = op.minimize(fun = regCostFunction, x0 = theta, args = (X, y),\n",
    "                         method = 'TNC', jac = regGradient)\n",
    "    \n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#계수를 저장할 변수\n",
    "all_theta = np.zeros((k, n + 1))\n",
    "\n",
    "#학습 수행\n",
    "i = 0\n",
    "for flower in Species:\n",
    "    #현재 구하고자하는 종은 1 아닌 값은 0\n",
    "    tmp_y = np.array(y_train == flower, dtype = int)\n",
    "    optTheta = logisticRegression(X_train, tmp_y, np.zeros((n + 1,1)))\n",
    "    all_theta[i] = optTheta\n",
    "    i += 1\n",
    "    \n",
    "print(all_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#추론부분\n",
    "P = sigmoid(X_test.dot(all_theta.T)) #각 종에 대한 모든 데이터의 확률값\n",
    "p = [Species[np.argmax(P[i, :])] for i in range(X_test.shape[0])] #추론된 확률 중 가장 높은 값을 채택하여 그 종으로 최종 추론\n",
    "\n",
    "print(\"테스트 세트 정확도:\", accuracy_score(y_test, p) * 100 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. scratch로 분류한 결과 확인하기\n",
    "행 값이 추론결과 열 값이 실제 값으로 이루어진 Confusion Matrix로 시각화 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_test, p, labels = Species)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cfm)\n",
    "\n",
    "ax.set_xticks(np.arange(len(Species)))\n",
    "ax.set_yticks(np.arange(len(Species)))\n",
    "\n",
    "ax.set_xticklabels(Species)\n",
    "ax.set_yticklabels(Species)\n",
    "\n",
    "for i in range(len(Species)):\n",
    "    for j in range(len(Species)):\n",
    "        text = ax.text(j, i, cfm[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"r\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. sklearn으로 분류해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, 2:4]\n",
    "Y = iris.target\n",
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "\n",
    "logreg.fit(X, Y)\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02\n",
    "#cmap_light = Mash에 표시될 3가지 색상\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "#cmap_bold = 학습 데이터를 표시할 3가지 색상\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=cmap_bold, s=15)\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. sklearn 결과 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)\n",
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial', max_iter = 1000)\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"학습 세트 정확도: {:.3f}%\".format(logreg.score(X_train, y_train) * 100))\n",
    "print(\"테스트 세트 정확도: {:.3f}%\".format(logreg.score(X_test, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:]\n",
    "y = iris.target\n",
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial', max_iter = 1000)\n",
    "\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape\n",
    "\n",
    "colors = (['aqua', 'darkorange', 'cornflowerblue'])\n",
    "\n",
    "classifier = OneVsRestClassifier(logreg)\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "plt.figure()\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sstest",
   "language": "python",
   "name": "sstest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
