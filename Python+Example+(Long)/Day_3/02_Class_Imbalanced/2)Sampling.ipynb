{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab03\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "#### Class Imbalanced\n",
    "+ Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling\n",
    "임의 추출은 데이터를 늘이거나(Oversample) 줄이기에(Undersample) 매우 편리한 방법입니다. <br>\n",
    "하지만, 임의 추출은 Oversample의 경우 기존의 데이터에서 임의로 선택된 데이터의 같은 위치에 새로운 점을 찍기 때문에 이후 모델의 과적합 우려가 있습니다.<br>\n",
    "또한, Undersample의 경우 임의로 제거하거나, 클러스터 기반으로 데이터를 제거하게 되는데 이로 인해 데이터의 손실이 생기기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE(Synthetic Minority Oversampling Technique)\n",
    "SMOTE의 기본 개념은 어렵지 않습니다. 수가 적은 클래스의 점을 하나 선택해 k개의 최근접 이웃을 찾고 그 사이에 새로운 점을 생성합니다.<br>\n",
    "SMOTE의 장점으로는 데이터의 손실이 없으며 복원 임의 추출로 Oversample을 하였을 때 보다 과적합을 완화 시킬 수 있습니다.\n",
    "<br>\n",
    "하지만, 새로운 점을 생성하는 동안 인접한 다른 점들을 고려하지 않기 때문에 추가적인 노이즈가 생길 수 있다는 단점도 있습니다.\n",
    "![SMOTE](./Images/SMOTE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 살펴보기\n",
    "Sklearn은 분류 모형의 테스트를 위해 make_classification, make_blob. make_gaussian_quantiles 등의 가상 데이터 생성 함수를 제공하고 있습니다.<br>\n",
    "이번 실습에서는 make_classification을 사용해 5천개의 샘플을 3개의 클래스에 대해 0.01, 0.05, 0.94 비율로 생성했습니다.<br>\n",
    "Random Over & Under Sample, SMOTE를 통해 샘플링 종류별 차이점을 확인해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0, n_classes=3,\n",
    "                           n_clusters_per_class=1,\n",
    "                           weights=[0.01, 0.05, 0.94],\n",
    "                           class_sep=0.8, random_state=0)\n",
    "\n",
    "kwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\n",
    "fig = plt.Figure(figsize=(12,6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, **kwarg_params)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Oversampling\n",
    "임의 Oversampling은 임의로 선택된 데이터의 비슷한 위치에 새로운 점을 생성하기 때문에 겉으로 보았을 때는 데이터 분포의 변화를 보기 어렵습니다.<br>\n",
    "이로 인해 기존의 데이터에 모델이 과적합되는 현상이 생길 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled, linewidth=0.5, edgecolor='black')\n",
    "plt.title(\"RandomOverSampler Output ($n_{class}=4700)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Undersampling\n",
    "임의 Undersampling은 임의로 데이터를 제거하기 때문에 데이터의 손실이 생겨나게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled, linewidth=0.5, edgecolor='black')\n",
    "plt.title(\"RandomUnderSampler Output ($n_{class}=64)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SMOTE\n",
    "마지막으로 SMOTE를 확인해 보겠습니다. SMOTE는 이전에도 말했듯이 Random Sample 의 단점인 데이터의 손실과 모델의 과적합을 완화 시킬 수 있다는 장점이 있었습니다.<br>\n",
    "실제 데이터의 분포를 보고 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "plt.scatter(X_resampled[:, 0], X_resampled[:, 1], c=y_resampled, linewidth=0.5, edgecolor='black')\n",
    "plt.title(\"SMOTE Output ($n_{class}=64)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전의 2가지 샘플링 방법보다 데이터의 분포를 유지하면서 새로운 위치에 데이터를 생성할 수 있었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "- imblearn - https://imbalanced-learn.readthedocs.io\n",
    "- dataset example - https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/under-sampling/plot_comparison_under_sampling.html#sphx-glr-auto-examples-under-sampling-plot-comparison-under-sampling-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sstest",
   "language": "python",
   "name": "sstest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
