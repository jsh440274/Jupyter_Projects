{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab03\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* 선형 회귀 분석\n",
    "\n",
    "단순 회귀 분석(독립변수의 개수: 1)\n",
    "\n",
    "$Y = B_0 + B_1X_1$\n",
    "\n",
    "다중 회귀 분석(독립 변수의 개수: 2개 이상)\n",
    "\n",
    "$Y = B_0 + B_1X_1 + B_2X_2+ \\cdot\\cdot\\cdot B_dX_d$\n",
    "    \n",
    "1. 모델이 적합한가\n",
    "    - $R^2$ (결정계수):\n",
    "      <br>  종속 변수의 총 변화량 중 모델이 잡아낼 수 있는 변화량의 비율\n",
    "![R2](./Images/R2.png)\n",
    "\n",
    "    (다중 회귀 분석에서는 독립변수의 수가 증가하면 함께 증가하는 $R^2$의 특징을 보완하는 수정된 $R^2$를 사용합니다.)\n",
    "    \n",
    "\n",
    "2. 선형 회귀 모델이 의미 있는가(회귀계수가 독립변수의 영향력을 잘 표현하는가)\n",
    "    - 독립변수들간 서로 독립적이어야 한다.(다중 공선성 문제가 없어야 합니다.)\n",
    "    \n",
    "    ex) Y = 2(X1) + 3(X2) <다중 공선성 문제가 있는 X1, X2>\n",
    "\n",
    "    => X1이 설명력 있는 독립 변수라면 p-value가 유의 수준보다 작아 유의한 통계량이 됩니다.\n",
    "\n",
    "    (문제 발생)그런데, X2가 설명할 부분을 X1이 가져가 버렸기 때문에 X2의 설명력은 작아지게 됩니다.\n",
    "\n",
    "    #### \\* 이를 방지하는 방법\n",
    "        ___\\- 변수 선택법(Feature Selection)으로 의존적인 변수 삭제하는 방법___\n",
    "        <br>\\- PCA(principal component analysis) 방법으로 의존적인 성분 삭제하는 방법\n",
    "        <br>\\- 정규화(regularized) 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 변수 선택법(Feature Selection)으로 의존적인 변수 삭제하는 방법\n",
    "\n",
    "### < Stepwise selection >\n",
    "\n",
    "### p-value 분석을 통한 변수 선택(Feature Selection)\n",
    "+ 가설 검정을 통해서 판단합니다.\n",
    "    + 귀무가설을 회귀 계수 = 0이라고 설정(회귀 계수가 유의미 하지 않다.)\n",
    "    + 그 회귀 계수가 유의미하다고 판단하면 기각\n",
    "\n",
    "\n",
    "+ 다중공선성이 생기면 해당 변수의 설명력은 약해집니다.\n",
    "+ 이는 변수의 표준오차의 증가로 드러납니다.\n",
    "+ 검정 통계량 = (추정된 회귀 계수 - H0) / 그 계수의 추정 표준 오차\n",
    "\n",
    "        1) 여기서 표준 오차는 표본의 실제관측치가 표본 회귀선상의 추정치에서 얼마나 흩어져 있나를 측정한 값입니다.\n",
    "\n",
    "        2) 표준오차가 작으면 작을수록 실제값과 추정값간의 차이가 없다고 볼수 있습니다.\n",
    "\n",
    "        3) 표준오차 구하기 \n",
    "<center>$s = \\sqrt{\\sum \\frac{(Y_i-\\hat{Y})^2}{n-2}}$\n",
    "\n",
    "        (추정표준오차의 제곱은 잔차의 분산입니다.)\n",
    "\n",
    "\n",
    "+ 이 검정 통계량의 절대값이 클수록 p-value는 작아져서(표준 오차가 커졌기 때문) 귀무가설을 기각할 수 있게 됩니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![stepwise2](./Images/stepwise_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in= 0.05, \n",
    "                       threshold_out = 0.01, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제\n",
    "__다중 회귀분석시 다중 공선성 문제 방지 방법__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('data','diabetesDataset.csv'))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dim in df.columns:\n",
    "        df[dim] -= np.min(df[dim])\n",
    "        df[dim] /= np.max(df[dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.hist(bins = 20, figsize=(10, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 상관관계분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Stepwise selection\n",
    "\n",
    "    통계적으로 유의미한 변수를 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = df[df.columns[:-1]]\n",
    "dfy = df[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in= 0.05, \n",
    "                       threshold_out = 0.01, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(dfx, dfy)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)\n",
    "\n",
    "newlabel = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diabetes_X_multi = df[newlabel].values.tolist()\n",
    "diabetes_Y_multi = df[['y']].values.tolist()\n",
    "\n",
    "# 선형회귀 추정기 생성\n",
    "lr = linear_model.LinearRegression() \n",
    "\n",
    "# input 대해 선형 회귀(모델 파라미터 추정)\n",
    "lr.fit(diabetes_X_multi, diabetes_Y_multi)\n",
    "\n",
    "# 회귀식으로 데이터의 결과 추정\n",
    "diabetes_y_pred_multi = lr.predict(diabetes_X_multi)\n",
    "\n",
    "# R2 scroe\n",
    "R2 = r2_score(diabetes_Y_multi, diabetes_y_pred_multi)\n",
    "print('R2 score: %.2f' % R2)\n",
    "\n",
    "# adj R2 score\n",
    "n = len(diabetes_X_multi)\n",
    "p = len(newlabel)\n",
    "\n",
    "Adj_r2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('Adj R2 score: %.2f' % Adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "newlabel = ['age', 'sex', 'bmi', 'map', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu']\n",
    "combs = []\n",
    "adj_list = []\n",
    "label_list = []\n",
    "for i in range(1, len(newlabel)+1):\n",
    "    els = [list(x) for x in itertools.combinations(newlabel, i)]\n",
    "    combs.extend(els) # list 원소만을 append(일반적인 append는 list 자체를 추가한다.)\n",
    "for i in range(len(combs)):\n",
    "    print('label', combs[i])\n",
    "    label_list.append(combs[i])\n",
    "    dfx = df[combs[i]].values.tolist()\n",
    "    dfy = df[['y']].values.tolist()\n",
    "    print(np.shape(dfx))\n",
    "\n",
    "    # 선형회귀 추정기 생성\n",
    "    lr2 = linear_model.LinearRegression()\n",
    "\n",
    "    # input 대해 선형 회귀(모델 파라미터 추정)\n",
    "    lr2.fit(dfx, dfy)\n",
    "\n",
    "    # 모델 파라미터 출력\n",
    "    print('Model parameters: \\n')\n",
    "    rgstr = ''\n",
    "    for j in range(len(lr2.coef_[0])):\n",
    "        print(\"b%d\" %(len(lr2.coef_[0])-j),\": \", \"%f\" %lr2.coef_[0,j])\n",
    "        rgstr = ' + '+repr(lr2.coef_[0,j]) + '*x'+repr(len(lr2.coef_[0])-j) + rgstr\n",
    "\n",
    "    print('b0:', lr2.intercept_[0])\n",
    "    print()\n",
    "    rgstr = repr(lr2.intercept_[0]) + rgstr\n",
    "    print('y = ', rgstr)\n",
    "\n",
    "    y_pred = lr2.predict(dfx)\n",
    "    n = len(dfx)\n",
    "    p = len(combs[i])\n",
    "\n",
    "    R2 = r2_score(dfy, y_pred)\n",
    "    Adj_r2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "    adj_list.append(Adj_r2)\n",
    "    print('Adj R2 score: %.2f' %  Adj_r2)\n",
    "    print('**************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Max Adj R2 score: %.2f' %  np.max(adj_list))\n",
    "print('Selected label :', label_list[np.argmax(adj_list)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 프로젝트\n",
    "배운 내용을 바탕으로 회귀 모델을 만들고 분석해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 시간 사용할 데이터는 Combined Cycle Power Plant Data Set입니다. 이 데이터 세트는 발전소가 최대 부하로 작동하도록 설정된 동안 수집된 데이터들입니다.\n",
    "5개의 컬럼을 가지고 있으며, 각 컬럼들은 시간별 평균 주변 변수로 구성됩니다.\n",
    "구성 값들은 매 초마다 주변 변수를 기록하는 공장 주변에 위치한 다양한 센서의 측정 값을 평균한 값입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Description\n",
    "- AT : 주변 온도(범위 1.81 - 37.11(°C))\n",
    "- V  : 배기 진공 압력()\n",
    "- AP : 주변 압력(범위 992.89 - 1033.30(milibar))\n",
    "- RH : 상대 습도(범위 25.56 - 100.16(%))\n",
    "- PE : 공장의 시간당 전기 에너지 출력(범위 420.26 - 495.76(MW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('data','Folds5x2_pp_1.csv'))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.간단한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dim in df.columns:\n",
    "        df[dim] -= np.min(df[dim])\n",
    "        df[dim] /= np.max(df[dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립변수와 종속변수를 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfx = df[df.columns[:-1]]\n",
    "dfy = df[['PE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfy.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 단순 선형 회귀 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "newlabel = df.columns[:-1]\n",
    "combs = []\n",
    "\n",
    "adj_list = []\n",
    "label_list = []\n",
    "\n",
    "\n",
    "els = [list(x) for x in itertools.combinations(newlabel, 1)]\n",
    "combs.extend(els) # list 원소만을 append(일반적인 append는 list 자체를 추가한다.)\n",
    "    \n",
    "for i in range(len(combs)):\n",
    "    print('label', combs[i])\n",
    "    label_list.append(combs[i])\n",
    "    dfx_tmp = dfx[combs[i]].values.tolist()\n",
    "    dfy_tmp = dfy.values.tolist()\n",
    "    print(np.shape(dfx_tmp))\n",
    "\n",
    "    # 선형회귀 추정기 생성\n",
    "    lr2 = linear_model.LinearRegression()\n",
    "\n",
    "    # input 대해 선형 회귀(모델 파라미터 추정)\n",
    "    lr2.fit(dfx_tmp, dfy_tmp)\n",
    "\n",
    "    # 모델 파라미터 출력\n",
    "    print('Model parameters: \\n')\n",
    "    rgstr = ''\n",
    "    for j in range(len(lr2.coef_[0])):\n",
    "        print(\"b%d\" %(len(lr2.coef_[0])-j),\": \", \"%f\" %lr2.coef_[0,j])\n",
    "        rgstr = ' + '+repr(lr2.coef_[0,j]) + '*x'+repr(len(lr2.coef_[0])-j) + rgstr\n",
    "\n",
    "    print('b0:', lr2.intercept_[0])\n",
    "    print()\n",
    "    rgstr = repr(lr2.intercept_[0]) + rgstr\n",
    "    print('y = ', rgstr)\n",
    "\n",
    "    y_pred = lr2.predict(dfx_tmp)\n",
    "    n = len(dfx_tmp)\n",
    "    p = len(combs[i])\n",
    "\n",
    "    R2 = r2_score(dfy_tmp, y_pred)\n",
    "    Adj_r2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "    adj_list.append(Adj_r2)\n",
    "    print('Adj R2 score: %.2f' %  Adj_r2)\n",
    "    \n",
    "    # Plot\n",
    "\n",
    "    # 데이터 좌표 plot\n",
    "    plt.scatter(dfx_tmp, dfy_tmp,  color='black', label='Data Point(patients)')\n",
    "\n",
    "    # 회귀 결과 plot\n",
    "    plt.plot(dfx_tmp, y_pred, color='blue', linewidth=3, label='Linear Regression')\n",
    "\n",
    "    # x축 label\n",
    "    plt.xlabel(combs[i])\n",
    "\n",
    "    #y축 label\n",
    "    plt.ylabel('PE')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print('**************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 다중 선형 회귀 분석 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scatter_matrix(df, figsize = (20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 종속변수인 PE와 다른 변수들간에 상관관계가 있다는 것을 확인할 수 있습니다.\n",
    "\n",
    "- V와 AT 변수간의 상관관계가 있음을 확인 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 다중공선성 방지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepwise selection\n",
    "\n",
    "    통계적으로 유의미한 변수를 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in= 0.05, \n",
    "                       threshold_out = 0.01, \n",
    "                       verbose=True):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(dfx, dfy)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)\n",
    "\n",
    "newlabel = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  회귀식 추정 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfx_multi = df[newlabel]\n",
    "dfy_multi = df[['PE']]\n",
    "\n",
    "# 선형회귀 추정기 생성\n",
    "lr = linear_model.LinearRegression() \n",
    "\n",
    "# input 대해 선형 회귀(모델 파라미터 추정)\n",
    "lr.fit(dfx_multi.values.tolist(), dfy_multi.values.tolist())\n",
    "\n",
    "# 회귀식으로 데이터의 결과 추정\n",
    "dfy_y_pred_multi = lr.predict(dfx_multi.values.tolist())\n",
    "\n",
    "# R2 scroe\n",
    "R2 = r2_score(dfy_multi.values.tolist(), dfy_y_pred_multi)\n",
    "print('R2 score: %.2f' % R2)\n",
    "\n",
    "# adj R2 score\n",
    "n = len(dfx_multi)\n",
    "p = len(newlabel)\n",
    "\n",
    "Adj_r2 = 1-(1-R2)*(n-1)/(n-p-1)\n",
    "print('Adj R2 score: %.2f' % Adj_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sstest",
   "language": "python",
   "name": "sstest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
